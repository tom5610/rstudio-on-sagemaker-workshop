{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Your Own R Algorithm with Your Own Container in Amazon SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Using Amazon SageMaker's Hyperparameter Tuning with a customer Docker container and R algorithm**_\n",
    "\n",
    "---\n",
    "\n",
    "**Read before running the notebook:**\n",
    "- This notebook has been updated to SageMaker v2.0\n",
    "- Use Python3 kernel for this notebook.\n",
    "- Dockerfile has been updated to use [Amazon ECR Public Gallery](https://docs.aws.amazon.com/AmazonECR/latest/public/public-gallery.html)\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "  1. [Permissions](#Permissions)\n",
    "1. [Code](#Code)\n",
    "  1. [Publish](#Publish)\n",
    "1. [Data](#Data)\n",
    "1. [Tune](#Tune)\n",
    "1. [HPO Analysis](#HPO-Analysis)\n",
    "1. [Host](#Host)\n",
    "1. [Predict](#Predict)\n",
    "1. [(Optional) Clean-up](#(Optional)-Clean-up)\n",
    "1. [Wrap-up](#Wrap-up)\n",
    "\n",
    "---\n",
    "## Background\n",
    "\n",
    "R is a popular open source statistical programming language, with a lengthy history in Data Science and Machine Learning.  The breadth of algorithms available as R packages is impressive and fuels a diverse community of users.  In this example, we'll combine one of those algorithms ([Multivariate Adaptive Regression Splines](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines)) with SageMaker's hyperparameter tuning capabilities to build a simple model on the well-known [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). \n",
    "\n",
    "\n",
    "This notebook will focus mainly on the integration of hyperparameter tuning and a custom algorithm container, as well as hosting the tuned model and making inference using the endpoint. For more examples, please see this [notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/r_bring_your_own/r_bring_your_own.ipynb).\n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the notebook instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/using-identity-based-policies.html) for more details on creating these.  Note, if a role not associated with the current notebook instance, or more than one role is required for training and/or hosting, please replace `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-hpo-r-byo\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import the libraries we'll need for the remainder of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permissions\n",
    "\n",
    "Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because we'll be creating a new repository in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role associated with your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately.\n",
    "\n",
    "---\n",
    "## Code\n",
    "\n",
    "For this example, we'll need 3 supporting code files.  We'll provide just a brief overview of what each one does.  See the full R bring your own notebook for more details.\n",
    "\n",
    "- **Fit**: `mars.R` creates functions to train and serve our model.\n",
    "- **Serve**: `plumber.R` uses the [plumber](https://www.rplumber.io/) package to create a lightweight HTTP server for processing requests in hosting.  Note the specific syntax, and see the plumber help docs for additional detail on more specialized use cases.\n",
    "- **Dockerfile**:  This specifies the configuration for our docker container.  Smaller containers are preferred for Amazon SageMaker as they lead to faster spin up times in training and endpoint creation, so this container is kept minimal. This docker file starts with base R image, installs `plumber` and `mda` libraries and their dependecies, then adds `mars.R` and `plumber.R`, and finally sets `mars.R` to run as the entrypoint when launched.\n",
    "\n",
    "    - **Upodate:** The updated dockerfile leverages public R-Base image from [Amazon Public ECR Gallery](https://aws.amazon.com/about-aws/whats-new/2020/12/announcing-amazon-ecr-public-and-amazon-ecr-public-gallery/) which has been available since December 2020. Feel free to read more about this public gallery and browse for public images at https://gallery.ecr.aws/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish\n",
    "Now, to publish this container to ECR, we'll run the comands below.\n",
    "\n",
    "This command will take several minutes to run the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_name = \"rmars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  77.31kB\n",
      "Step 1/8 : FROM public.ecr.aws/docker/library/r-base:latest\n",
      " ---> 16511f39cdb4\n",
      "Step 2/8 : MAINTAINER Amazon SageMaker Examples <amazon-sagemaker-examples@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 0669b86a8779\n",
      "Step 3/8 : RUN apt-get -y update && apt-get install -y --no-install-recommends     apt-utils     wget     r-base     r-base-dev     libcurl4-openssl-dev     apt-transport-https     libsodium-dev     ca-certificates\n",
      " ---> Using cache\n",
      " ---> 5ee2e6615c92\n",
      "Step 4/8 : RUN apt-get install -y --no-install-recommends     libjs-bootstrap     libjs-jquery     r-api-4.0     r-cran-crayon     r-cran-httpuv     r-cran-jsonlite     r-cran-lifecycle     r-cran-magrittr     r-cran-mime     r-cran-promises     r-cran-r6     r-cran-sodium     r-cran-stringi     r-cran-swagger     r-cran-webutils     r-cran-plumber\n",
      " ---> Using cache\n",
      " ---> 505aee30120b\n",
      "Step 5/8 : RUN apt-get install -y --no-install-recommends     libc6     libgfortran5     r-cran-class     r-cran-testthat     r-cran-mda\n",
      " ---> Using cache\n",
      " ---> 8cc5538910f2\n",
      "Step 6/8 : COPY mars.R /opt/ml/mars.R\n",
      " ---> Using cache\n",
      " ---> fedb8f11e186\n",
      "Step 7/8 : COPY plumber.R /opt/ml/plumber.R\n",
      " ---> Using cache\n",
      " ---> 2b981cb3dad7\n",
      "Step 8/8 : ENTRYPOINT [\"/usr/bin/Rscript\", \"/opt/ml/mars.R\", \"--no-save\"]\n",
      " ---> Using cache\n",
      " ---> f59290218eed\n",
      "Successfully built f59290218eed\n",
      "Successfully tagged rmars:latest\n",
      "The push refers to repository [482851446821.dkr.ecr.us-east-1.amazonaws.com/rmars]\n",
      "c0efcef22814: Preparing\n",
      "c84a6e9772a6: Preparing\n",
      "d67c074223e8: Preparing\n",
      "03574579efbd: Preparing\n",
      "3a1850bf26de: Preparing\n",
      "c268156c8470: Preparing\n",
      "aab763483f1a: Preparing\n",
      "8926fee97375: Preparing\n",
      "51a800daf041: Preparing\n",
      "b795496cd7e9: Preparing\n",
      "2be7c7a88cfa: Preparing\n",
      "c268156c8470: Waiting\n",
      "aab763483f1a: Waiting\n",
      "8926fee97375: Waiting\n",
      "51a800daf041: Waiting\n",
      "b795496cd7e9: Waiting\n",
      "2be7c7a88cfa: Waiting\n",
      "03574579efbd: Layer already exists\n",
      "c0efcef22814: Layer already exists\n",
      "3a1850bf26de: Layer already exists\n",
      "d67c074223e8: Layer already exists\n",
      "c84a6e9772a6: Layer already exists\n",
      "c268156c8470: Layer already exists\n",
      "aab763483f1a: Layer already exists\n",
      "51a800daf041: Layer already exists\n",
      "b795496cd7e9: Layer already exists\n",
      "8926fee97375: Layer already exists\n",
      "2be7c7a88cfa: Layer already exists\n",
      "latest: digest: sha256:e2b5e42ad732c776541cad74ce740671f7ce0001772608f10536460c759f8235 size: 2630\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=rmars\n",
    "\n",
    "#set -e # stop if anything fails\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "For this illustrative example, we'll simply use `iris`.  This a classic, but small, dataset used to test supervised learning algorithms.  Typically, the goal is to predict one of three flower species based on various measurements of the flowers' attributes.  Further details can be found [here](https://archive.ics.uci.edu/ml/datasets/iris).\n",
    "* **Source:** Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Let's split the data to train and test datasets (70% / 30%) and then copy the data to S3 so that SageMaker training can access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/fsspec/registry.py:279: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\", \"Species\"]\n",
    "data = pd.read_csv(\n",
    "    \"s3://sagemaker-sample-files/datasets/tabular/iris/iris.data\",\n",
    "    names=column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width      Species\n",
       "1            4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2            4.7          3.2           1.3          0.2  Iris-setosa\n",
       "6            4.6          3.4           1.4          0.3  Iris-setosa\n",
       "14           5.8          4.0           1.2          0.2  Iris-setosa\n",
       "20           5.4          3.4           1.7          0.2  Iris-setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test split, 70%-30%\n",
    "train_data = data.sample(frac=0.7, random_state=42)\n",
    "test_data = data.drop(train_data.index)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "train_data.to_csv(\"iris_train.csv\", index=False)\n",
    "test_data.to_csv(\"iris_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to S3\n",
    "train_file = \"iris_train.csv\"\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train\", train_file)\n",
    ").upload_file(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: Although we could do preliminary data transformations in the notebook, we'll avoid doing so, instead choosing to do those transformations inside the container.  This is not typically the best practice for model efficiency, but provides some benefits in terms of flexibility._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tune\n",
    "\n",
    "Now, let's setup the information needed to train a Multivariate Adaptive Regression Splines model on `iris` data.  In this case, we'll predict `Sepal.Length` rather than the more typical classification of `Species` in order to show how factors might be included in a model and to limit the use case to regression.\n",
    "\n",
    "First, we'll get our region and account information so that we can point to the ECR container we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "account = boto3.client(\"sts\").get_caller_identity().get(\"Account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create an estimator using the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk).  This allows us to specify:\n",
    "- The training container image in ECR\n",
    "- The IAM role that controls permissions for accessing the S3 data and executing SageMaker functions\n",
    "- Number and type of training instances\n",
    "- S3 path for model artifacts to be output to\n",
    "- Any hyperparameters that we want to have the same value across all training jobs during tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=\"{}.dkr.ecr.{}.amazonaws.com/rmars:latest\".format(account, region),\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    hyperparameters={\"degree\": 2},\n",
    ")  # Setting constant hyperparameter\n",
    "\n",
    "# target is by defauld \"Sepal.Length\". See mars.R where this is set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've defined our estimator we can specify the hyperparameters that we'd like to tune and their possible values.  We have three different types of hyperparameters.\n",
    "- Categorical parameters need to take one value from a discrete set.  We define this by passing the list of possible values to `CategoricalParameter(list)`\n",
    "- Continuous parameters can take any real number value between the minimum and maximum value, defined by `ContinuousParameter(min, max)`\n",
    "- Integer parameters can take any integer value between the minimum and maximum value, defined by `IntegerParameter(min, max)`\n",
    "\n",
    "*Note, if possible, it's almost always best to specify a value as the least restrictive type.  For example, tuning `thresh` as a continuous value between 0.01 and 0.2 is likely to yield a better result than tuning as a categorical parameter with possible values of 0.01, 0.1, 0.15, or 0.2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set the degree as a varying HP to tune, use: 'degree': IntegerParameter(1, 3) and remove it from the Estimator\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"thresh\": ContinuousParameter(0.001, 0.01),\n",
    "    \"prune\": CategoricalParameter([\"TRUE\", \"FALSE\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll specify the objective metric that we'd like to tune and its definition.  This metric is output by a `print` statement in our `mars.R` file.  Its critical that the format aligns with the regular expression (Regex) we then specify to extract that metric from the CloudWatch logs of our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"mse\"\n",
    "metric_definitions = [{\"Name\": \"mse\", \"Regex\": \"mse: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a `HyperparameterTuner` object, which we pass:\n",
    "- The MXNet estimator we created above\n",
    "- Our hyperparameter ranges\n",
    "- Objective metric name and definition\n",
    "- Whether we should maximize or minimize our objective metric (defaults to 'Maximize')\n",
    "- Number of training jobs to run in total and how many training jobs should be run simultaneously.  More parallel jobs will finish tuning sooner, but may sacrifice accuracy.  We recommend you set the parallel jobs value to less than 10% of the total number of training jobs (we'll set it higher just for this example to keep it short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    objective_type=\"Minimize\",\n",
    "    max_jobs=9,\n",
    "    max_parallel_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can start our hyperparameter tuning job by calling `.fit()` and passing in the S3 paths to our train and test datasets.\n",
    "\n",
    "*Note, typically for hyperparameter tuning, we'd want to specify both a training and validation (or test) dataset and optimize the objective metric from the validation dataset.  However, because `iris` is a very small dataset we'll skip the step of splitting into training and validation.  In practice, doing this could lead to a model that overfits to our training data and does not generalize well.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"train\": \"s3://{}/{}/train\".format(bucket, prefix)}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just run a quick check of the hyperparameter tuning jobs status to make sure it started successfully and is `InProgress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress, Completed Jobs: 0, In Progress Jobs: 3\n",
      "InProgress, Completed Jobs: 0, In Progress Jobs: 3\n",
      "InProgress, Completed Jobs: 0, In Progress Jobs: 3\n",
      "InProgress, Completed Jobs: 2, In Progress Jobs: 3\n",
      "InProgress, Completed Jobs: 5, In Progress Jobs: 1\n",
      "InProgress, Completed Jobs: 6, In Progress Jobs: 3\n",
      "InProgress, Completed Jobs: 8, In Progress Jobs: 1\n",
      "Completed, Completed Jobs: 9, In Progress Jobs: 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "while status != \"Completed\":\n",
    "    status = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "    completed = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "\n",
    "    prog = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"TrainingJobStatusCounters\"][\"InProgress\"]\n",
    "\n",
    "    print(f\"{status}, Completed Jobs: {completed}, In Progress Jobs: {prog}\")\n",
    "\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the HPO job is complete, and then run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobName': 'rmars-240723-0437-003-28f16cd8',\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:482851446821:training-job/rmars-240723-0437-003-28f16cd8',\n",
       " 'CreationTime': datetime.datetime(2024, 7, 23, 4, 38, 7, tzinfo=tzlocal()),\n",
       " 'TrainingStartTime': datetime.datetime(2024, 7, 23, 4, 38, 49, tzinfo=tzlocal()),\n",
       " 'TrainingEndTime': datetime.datetime(2024, 7, 23, 4, 39, 48, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'TunedHyperParameters': {'prune': 'FALSE', 'thresh': '0.004049633760804366'},\n",
       " 'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'mse',\n",
       "  'Value': 6.68666934967041},\n",
       " 'ObjectiveStatus': 'Succeeded'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"BestTrainingJob\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## HPO Analysis\n",
    "\n",
    "Now that we've started our hyperparameter tuning job, it will run in the background and we can close this notebook.  Once finished, we can use the [HPO Analysis notebook](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) to determine which set of hyperparameters worked best.\n",
    "\n",
    "For more detail on Amazon SageMaker's Hyperparameter Tuning, please refer to the AWS documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Hosting the model we just tuned takes three steps in Amazon SageMaker.  First, we define the model we want to host, pointing the service to the model artifact our training job just wrote to S3.\n",
    "\n",
    "We will use the results of the HPO for this purpose, but using `hyper_parameter_tuning_job` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"BestTrainingJob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-482851446821/sagemaker/DEMO-hpo-r-byo/output/rmars-240723-0437-003-28f16cd8/output/model.tar.gz'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best trainig job and S3 location for the model file\n",
    "best_model_s3 = boto3.client(\"sagemaker\").describe_training_job(\n",
    "    TrainingJobName=best_training[\"TrainingJobName\"]\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "best_model_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "r_job = \"DEMO-r-byo-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:482851446821:model/DEMO-r-byo-2024-07-23-04-45-20\n"
     ]
    }
   ],
   "source": [
    "r_hosting_container = {\n",
    "    \"Image\": \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, algorithm_name),\n",
    "    \"ModelDataUrl\": best_model_s3,\n",
    "}\n",
    "\n",
    "create_model_response = boto3.client(\"sagemaker\").create_model(\n",
    "    ModelName=r_job, ExecutionRoleArn=role, PrimaryContainer=r_hosting_container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create an endpoing configuration, passing in the model we just registered.  In this case, we'll only use a few c4.xlarges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-r-byo-config-2024-07-23-04-45-21\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:482851446821:endpoint-config/DEMO-r-byo-config-2024-07-23-04-45-21\n"
     ]
    }
   ],
   "source": [
    "r_endpoint_config = \"DEMO-r-byo-config-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(r_endpoint_config)\n",
    "\n",
    "create_endpoint_config_response = boto3.client(\"sagemaker\").create_endpoint_config(\n",
    "    EndpointConfigName=r_endpoint_config,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": r_job,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll create the endpoints using our endpoint configuration from the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-r-endpoint-202407230445\n",
      "arn:aws:sagemaker:us-east-1:482851446821:endpoint/DEMO-r-endpoint-202407230445\n",
      "Status: Creating\n",
      "Arn: arn:aws:sagemaker:us-east-1:482851446821:endpoint/DEMO-r-endpoint-202407230445\n",
      "Status: InService\n",
      "CPU times: user 107 ms, sys: 12.7 ms, total: 120 ms\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r_endpoint = \"DEMO-r-endpoint-\" + time.strftime(\"%Y%m%d%H%M\", time.gmtime())\n",
    "print(r_endpoint)\n",
    "create_endpoint_response = boto3.client(\"sagemaker\").create_endpoint(\n",
    "    EndpointName=r_endpoint, EndpointConfigName=r_endpoint_config\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = boto3.client(\"sagemaker\").describe_endpoint(EndpointName=r_endpoint)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "try:\n",
    "    boto3.client(\"sagemaker\").get_waiter(\"endpoint_in_service\").wait(EndpointName=r_endpoint)\n",
    "finally:\n",
    "    resp = boto3.client(\"sagemaker\").describe_endpoint(EndpointName=r_endpoint)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "    if status != \"InService\":\n",
    "        raise Exception(\"Endpoint creation did not succeed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predict\n",
    "To confirm our endpoints are working properly, let's try to invoke the endpoint.\n",
    "\n",
    "_Note: The payload we're passing in the request is a CSV string with a header record, followed by multiple new lines.  It also contains text columns, which the serving code converts to the set of indicator variables needed for our model predictions.  Again, this is not a best practice for highly optimized code, however, it showcases the flexibility of bringing your own algorithm._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "iris_test = pd.read_csv(\"iris_test.csv\")\n",
    "\n",
    "runtime = boto3.Session().client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.63324327982493,4.80044511788773,4.9863289466641,5.23172030182186,5.05858590531148,5.24070314228686,4.76937655218207,3.55288534714371,5.27953163889477,5.17620611454173,6.1318693029285,6.25071620311115,6.12149400345727,5.14424047777516,6.0997711065632,5.69949288189905,5.99805512192479,6.16123806202157,5.79493080854062,5.96713066520703,5.40603582289417,5.9410692580294,5.91130138610351,5.98144578513731,6.12231111525494,5.72105106121319,5.84610602250233,7.17025319136242,6.94315420341912,6.47572230628897,5.72822541764846,7.21237615541374,6.51631007231049,6.5473915546383,6.48360200083876,6.07047328441353,6.75027496362148,6.08287598299863,6.6689680481329,6.94943555116772,6.59565735351025,6.75298292199343,6.67782045127373,6.40339216676571,6.34758171409982']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 ms, sys: 3.62 ms, total: 18.5 ms\n",
      "Wall time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# there is a limit of max 500 samples at a time for invoking endpoints\n",
    "payload = iris_test.drop([\"Sepal.Length\"], axis=1).to_csv(index=False)\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=r_endpoint, ContentType=\"text/csv\", Body=payload)\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the result is a CSV of predictions for our target variable.  Let's compare them to the actuals to see how our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.scatter(iris_test[\"Sepal.Length\"], np.fromstring(result[0], sep=\",\"), alpha=0.4, s=50)\n",
    "plt.xlabel(\"Sepal Length(Actual)\")\n",
    "plt.ylabel(\"Sepal Length(Prediction)\")\n",
    "x = np.linspace(*plt.xlim())\n",
    "plt.plot(x, x, linestyle=\"--\", color=\"g\", linewidth=1)\n",
    "plt.xlim(4, 8)\n",
    "plt.ylim(4, 8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Clean-up\n",
    "\n",
    "If you're ready to be done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client(\"sagemaker\").delete_endpoint(EndpointName=r_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/r_examples|r_byo_r_algo_hpo|tune_r_bring_your_own.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
